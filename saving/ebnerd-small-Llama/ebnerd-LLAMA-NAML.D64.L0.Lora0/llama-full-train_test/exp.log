[00:00:00] |Worker| START TIME: 2024-06-12 13:10:39.577829
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:16:14.021912
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:16:43.761825
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:17:16.966312
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:19:01.730144
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:20:31.154573
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:24:17.421269
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:26:21.496706
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:27:39.048174
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:29:11.575383
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:35:45.631237
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:36:58.821826
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:42:07.278662
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:47:25.694446
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:51:05.242894
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:02:12.934832
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:03:28.997389
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:08:10.192773
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:08:43.798589
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:15:24.203875
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:16:30.008303
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:16:49.658977
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:20:35.819965
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:21:43.810601
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:22:53.737010
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:23:58.734361
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:27:03.272485
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:27:52.226633
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:31:57.375385
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:32:40.717218
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:33:14.577394
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:35:07.100039
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:40:46.401108
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:43:40.094777
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:44:04.817139
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:45:37.719245
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:47:43.317696
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:50:39.054209
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:51:30.107419
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:54:00.757992
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:54:33.710962
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:55:39.491565
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:09:32.602494
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:15:36.706763
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:17:49.496199
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:21:42.958257
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:23:46.396428
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:24:50.356081
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "LLama",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:33:38.002200
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Llama",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:34:33.693588
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Llama",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:37:10.017098
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Llama",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:02] |Controller| Selected Item Encoder: LlamaOperator
[00:00:02] |Controller| Selected User Encoder: LlamaOperator
[00:00:02] |Controller| Selected Predictor: DotPredictor
[00:00:02] |Controller| Use Negative Sampling: False
[00:00:02] |Controller| Use Item Content: True
[00:00:00] |Worker| START TIME: 2024-06-12 15:45:02.792316
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Llama",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:03] |Controller| Selected Item Encoder: LlamaOperator
[00:00:03] |Controller| Selected User Encoder: LlamaOperator
[00:00:03] |Controller| Selected Predictor: DotPredictor
[00:00:03] |Controller| Use Negative Sampling: False
[00:00:03] |Controller| Use Item Content: True
[00:00:00] |Worker| START TIME: 2024-06-12 15:50:32.435635
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Llama",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:02] |Controller| Selected Item Encoder: LlamaOperator
[00:00:02] |Controller| Selected User Encoder: LlamaOperator
[00:00:02] |Controller| Selected Predictor: DotPredictor
[00:00:02] |Controller| Use Negative Sampling: False
[00:00:02] |Controller| Use Item Content: True
[00:00:00] |Worker| START TIME: 2024-06-12 16:05:22.595339
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Llama",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:02] |Controller| Selected Item Encoder: LlamaOperator
[00:00:02] |Controller| Selected User Encoder: LlamaOperator
[00:00:02] |Controller| Selected Predictor: DotPredictor
[00:00:02] |Controller| Use Negative Sampling: False
[00:00:02] |Controller| Use Item Content: True
[00:00:00] |Worker| START TIME: 2024-06-12 16:05:44.769300
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Llama",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:02] |Controller| Selected Item Encoder: LlamaOperator
[00:00:02] |Controller| Selected User Encoder: LlamaOperator
[00:00:02] |Controller| Selected Predictor: DotPredictor
[00:00:02] |Controller| Use Negative Sampling: False
[00:00:02] |Controller| Use Item Content: True
[00:00:00] |Worker| START TIME: 2024-06-12 18:39:23.975986
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |Worker| START TIME: 2024-06-12 18:39:48.847277
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |Worker| START TIME: 2024-06-12 18:44:16.813642
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |Worker| START TIME: 2024-06-12 18:47:09.708773
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |Worker| START TIME: 2024-06-14 14:26:14.676264
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:01] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:01] |EmbeddingHub| skip col article_id
[00:00:01] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:02:22] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-14 14:38:00.626724
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:01] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:01] |EmbeddingHub| skip col article_id
[00:00:01] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:03:44] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-14 14:47:39.201090
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:01] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:02:01] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-14 16:37:01.327446
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:01] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:01] |EmbeddingHub| skip col article_id
[00:00:01] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:02:33] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-14 16:46:01.674301
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:01] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:02:09] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-14 16:49:38.933240
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:00] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:00:52] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-14 16:51:49.339809
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:00] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:00] |EmbeddingHub| build mapping title -> llama
[00:00:00] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:00:59] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-14 16:55:52.056435
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:00] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:00] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:01:17] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-14 17:07:46.797326
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:01] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:01:26] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-14 17:09:41.536153
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:00] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:00] |EmbeddingHub| build mapping title -> llama
[00:00:00] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:00:52] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-14 17:11:52.536199
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:00:51] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 13:08:07.911201
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:01] |Controller| Selected Item Encoder: LlamaOperator
[00:00:01] |Controller| Selected User Encoder: AdaOperator
[00:00:01] |Controller| Selected Predictor: DotPredictor
[00:00:01] |Controller| Use Negative Sampling: False
[00:00:01] |Controller| Use Item Content: True
[00:00:01] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:01] |EmbeddingHub| skip col article_id
[00:00:01] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:02] |EmbeddingHub| build mapping subtitle -> llama
[00:00:02] |EmbeddingHub| build mapping body -> llama
[00:00:02] |EmbeddingHub| build mapping category_str -> llama
[00:00:02] |EmbeddingHub| build mapping article_type -> llama
[00:00:02] |EmbeddingHub| build mapping topics -> topics
[00:00:02] |EmbeddingHub| create vocab topics (78, 4096)
[00:01:36] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 13:18:18.569694
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:00] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:00] |EmbeddingHub| build mapping title -> llama
[00:00:00] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:01:33] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 13:27:17.565600
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:01] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:01] |EmbeddingHub| skip col article_id
[00:00:01] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:01:11] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 13:28:58.109930
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:00] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:00:46] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 13:34:35.752774
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:00:48] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 13:55:59.134214
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:01] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:01] |EmbeddingHub| skip col article_id
[00:00:01] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:01:29] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 14:05:42.451122
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:00] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:00] |EmbeddingHub| build mapping title -> llama
[00:00:00] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:00:55] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 14:11:13.823422
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:01] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:01] |EmbeddingHub| skip col article_id
[00:00:01] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:02] |EmbeddingHub| build mapping subtitle -> llama
[00:00:02] |EmbeddingHub| build mapping body -> llama
[00:00:02] |EmbeddingHub| build mapping category_str -> llama
[00:00:02] |EmbeddingHub| build mapping article_type -> llama
[00:00:02] |EmbeddingHub| build mapping topics -> topics
[00:00:02] |EmbeddingHub| create vocab topics (78, 4096)
[00:01:33] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 14:22:01.153861
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:00] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:00] |EmbeddingHub| build mapping title -> llama
[00:00:00] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:01:22] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 15:11:43.748746
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:01] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:01] |EmbeddingHub| skip col article_id
[00:00:01] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:01:28] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 15:14:06.040504
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:00:49] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 15:34:03.436137
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:01] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:01] |EmbeddingHub| skip col article_id
[00:00:01] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:01:08] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object), 'max_length_article_ids_clicked': array([100], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 15:36:30.883005
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:00] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:00] |EmbeddingHub| build mapping title -> llama
[00:00:00] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:00:51] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object), 'max_length_article_ids_clicked': array([100], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 15:42:42.677608
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:01:24] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object), 'max_length_article_ids_clicked': array([100], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 15:47:53.559070
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:01] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:01] |EmbeddingHub| skip col article_id
[00:00:01] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:01:24] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object), 'max_length_article_ids_clicked': array([100], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 15:51:03.752326
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:00] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:00] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:01:09] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object), 'max_length_article_ids_clicked': array([100], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 15:53:50.401450
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:01] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:01] |EmbeddingHub| skip col article_id
[00:00:01] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:02:22] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object), 'max_length_article_ids_clicked': array([100], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 15:57:53.884225
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:00] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:00:49] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object), 'max_length_article_ids_clicked': array([100], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 15:59:49.400465
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:00] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:00] |EmbeddingHub| build mapping title -> llama
[00:00:00] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:00:48] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object), 'max_length_article_ids_clicked': array([100], dtype=object)}
[00:00:00] |Worker| START TIME: 2024-06-15 16:03:18.180054
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:00:54] |Worker| {'index': 0, 'impression_id': 0, 'user_id': 0, 'article_id': 11176, 'article_ids_clicked': array([0], dtype=object), 'max_length_article_ids_clicked': array([100], dtype=object)}
[00:00:55] |Worker| {
    "article_id": {
        "input_ids": {
            "natural_cat": "tensor([1, 601], dtype=torch.int64)"
        },
        "attention_mask": "tensor([1, 601], dtype=torch.int64)"
    },
    "article_ids_clicked": {
        "input_ids": {
            "natural_cat": "tensor([100, 601], dtype=torch.int64)"
        },
        "attention_mask": "tensor([100, 601], dtype=torch.int64)"
    },
    "impression_id": "int",
    "user_id": "int",
    "max_length_article_ids_clicked": "int",
    "__clicks_mask__": "tensor([100], dtype=torch.int64)"
}
[00:00:55] |Worker| split item pretrained encoder parameters
[00:00:55] |Worker| pretrained lr: 1e-05
[00:00:55] |Worker| other lr: 0.0001
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.0.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.0.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.0.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.0.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.0.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.0.input_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.0.post_attention_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.1.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.1.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.1.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.1.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.1.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.1.input_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.1.post_attention_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.2.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.2.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.2.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.2.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.2.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.2.input_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.2.post_attention_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.3.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.3.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.3.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.3.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.3.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.3.input_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.3.post_attention_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.4.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.4.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.4.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.4.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.4.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.4.input_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.4.post_attention_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.5.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.5.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.5.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.5.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.5.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.5.input_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.5.post_attention_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.6.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.6.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.6.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.6.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.6.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.6.input_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.6.post_attention_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.7.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.7.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.7.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.7.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.7.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.7.input_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.7.post_attention_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.8.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.8.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.8.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.8.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.8.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.8.input_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.8.post_attention_layernorm.weight torch.Size([4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.9.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.9.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:55] |Legommender| [P] item_encoder.transformer.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.9.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.9.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.9.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.9.input_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.9.post_attention_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.10.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.10.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.10.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.10.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.10.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.10.input_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.10.post_attention_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.11.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.11.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.11.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.11.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.11.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.11.input_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.11.post_attention_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.12.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.12.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.12.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.12.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.12.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.12.input_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.12.post_attention_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.13.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.13.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.13.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.13.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.13.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.13.input_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.13.post_attention_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.14.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.14.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.14.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.14.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.14.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.14.input_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.14.post_attention_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.15.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.15.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.15.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.15.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.15.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.15.input_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.15.post_attention_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.16.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.16.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.16.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.16.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.16.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.16.input_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.16.post_attention_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.17.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.17.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.17.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.17.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.17.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.17.input_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.17.post_attention_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.18.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.18.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.18.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.18.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.18.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.18.input_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.18.post_attention_layernorm.weight torch.Size([4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.19.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:56] |Legommender| [P] item_encoder.transformer.layers.19.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.19.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.19.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.19.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.19.input_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.19.post_attention_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.20.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.20.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.20.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.20.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.20.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.20.input_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.20.post_attention_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.21.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.21.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.21.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.21.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.21.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.21.input_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.21.post_attention_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.22.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.22.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.22.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.22.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.22.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.22.input_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.22.post_attention_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.23.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.23.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.23.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.23.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.23.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.23.input_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.23.post_attention_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.24.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.24.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.24.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.24.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.24.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.24.input_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.24.post_attention_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.25.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.25.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.25.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.25.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.25.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.25.input_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.25.post_attention_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.26.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.26.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.26.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.26.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.26.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.26.input_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.26.post_attention_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.27.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.27.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.27.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.27.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.27.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.27.input_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.27.post_attention_layernorm.weight torch.Size([4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.28.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.28.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.28.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.28.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.28.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:57] |Legommender| [P] item_encoder.transformer.layers.28.input_layernorm.weight torch.Size([4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.28.post_attention_layernorm.weight torch.Size([4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.29.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.29.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.29.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.29.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.29.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.29.input_layernorm.weight torch.Size([4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.29.post_attention_layernorm.weight torch.Size([4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.30.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.30.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.30.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.30.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.30.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.30.input_layernorm.weight torch.Size([4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.30.post_attention_layernorm.weight torch.Size([4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.31.self_attn.k_proj.weight torch.Size([4096, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.31.self_attn.v_proj.weight torch.Size([4096, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.31.mlp.gate_proj.weight torch.Size([11008, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.31.mlp.down_proj.weight torch.Size([4096, 11008])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.31.mlp.up_proj.weight torch.Size([11008, 4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.31.input_layernorm.weight torch.Size([4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.layers.31.post_attention_layernorm.weight torch.Size([4096])
[00:00:58] |Legommender| [P] item_encoder.transformer.norm.weight torch.Size([4096])
[00:00:58] |Legommender| [N] embedding_table.__cat_inputer_special_ids.weight torch.Size([3, 4096])
[00:00:58] |Legommender| [N] embedding_table.__flatten_seq_special_ids.weight torch.Size([4, 4096])
[00:00:58] |Legommender| [N] embedding_table.llama.weight torch.Size([32000, 4096])
[00:00:58] |Legommender| [N] embedding_table.topics.weight torch.Size([78, 4096])
[00:00:58] |Legommender| [N] user_encoder.additive_attention.encoder.0.weight torch.Size([256, 64])
[00:00:58] |Legommender| [N] user_encoder.additive_attention.encoder.0.bias torch.Size([256])
[00:00:58] |Legommender| [N] user_encoder.additive_attention.encoder.2.weight torch.Size([1, 256])
[00:00:58] |Legommender| [N] item_encoder.linear.weight torch.Size([64, 4096])
[00:00:58] |Legommender| [N] item_encoder.linear.bias torch.Size([64])
[00:00:58] |Legommender| [N] item_encoder.additive_attention.encoder.0.weight torch.Size([64, 64])
[00:00:58] |Legommender| [N] item_encoder.additive_attention.encoder.0.bias torch.Size([64])
[00:00:58] |Legommender| [N] item_encoder.additive_attention.encoder.2.weight torch.Size([1, 64])
[00:00:00] |Worker| START TIME: 2024-06-15 16:07:52.096745
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |Controller| Selected Item Encoder: LlamaOperator
[00:00:00] |Controller| Selected User Encoder: AdaOperator
[00:00:00] |Controller| Selected Predictor: DotPredictor
[00:00:00] |Controller| Use Negative Sampling: False
[00:00:00] |Controller| Use Item Content: True
[00:00:00] |EmbeddingHub| load pretrained embedding article_id of torch.Size([32000, 4096])
[00:00:00] |EmbeddingHub| skip col article_id
[00:00:00] |EmbeddingHub| create vocab __cat_inputer_special_ids (3, 4096)
[00:00:01] |EmbeddingHub| create vocab __flatten_seq_special_ids (4, 4096)
[00:00:01] |EmbeddingHub| build mapping title -> llama
[00:00:01] |EmbeddingHub| create vocab llama (32000, 4096)
[00:00:01] |EmbeddingHub| build mapping subtitle -> llama
[00:00:01] |EmbeddingHub| build mapping body -> llama
[00:00:01] |EmbeddingHub| build mapping category_str -> llama
[00:00:01] |EmbeddingHub| build mapping article_type -> llama
[00:00:01] |EmbeddingHub| build mapping topics -> topics
[00:00:01] |EmbeddingHub| create vocab topics (78, 4096)
[00:00:00] |Worker| START TIME: 2024-06-15 16:08:32.871083
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |Worker| START TIME: 2024-06-15 16:08:55.412253
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |Worker| START TIME: 2024-06-15 16:09:55.822785
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |Worker| START TIME: 2024-06-15 16:18:08.036118
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |Worker| START TIME: 2024-06-15 16:21:37.134063
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\llama-token.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama_converted_test",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama_converted_test"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index",
            "max_clicks": "max_length_article_ids_clicked"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11730)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11751)
        	article_ids_clicked, vocab article_ids_clicked (size 2)
        	max_length_article_ids_clicked, vocab max_length_article_ids_clicked (size 101)

