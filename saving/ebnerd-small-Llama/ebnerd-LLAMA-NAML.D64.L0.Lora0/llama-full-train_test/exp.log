[00:00:00] |Worker| START TIME: 2024-06-12 13:10:39.577829
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:16:14.021912
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:16:43.761825
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:17:16.966312
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:19:01.730144
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:20:31.154573
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:24:17.421269
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:26:21.496706
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:27:39.048174
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:29:11.575383
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:35:45.631237
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:36:58.821826
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:42:07.278662
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:47:25.694446
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 13:51:05.242894
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "/home/data1/qijiong/llama-7b",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "data/ebnerd-small-Llama/llama-7b-split"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:02:12.934832
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:03:28.997389
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:08:10.192773
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:08:43.798589
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:15:24.203875
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:16:30.008303
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:16:49.658977
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:20:35.819965
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:21:43.810601
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:22:53.737010
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:23:58.734361
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:27:03.272485
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:27:52.226633
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:31:57.375385
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:32:40.717218
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:33:14.577394
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:35:07.100039
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:40:46.401108
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:43:40.094777
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:44:04.817139
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:45:37.719245
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:47:43.317696
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:50:39.054209
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:51:30.107419
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:54:00.757992
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:54:33.710962
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 14:55:39.491565
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:09:32.602494
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:15:36.706763
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:17:49.496199
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:21:42.958257
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:23:46.396428
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Ada",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:24:50.356081
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "LLama",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:33:38.002200
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Llama",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:34:33.693588
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Llama",
            "predictor": "dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |Worker| START TIME: 2024-06-12 15:37:10.017098
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Llama",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:02] |Controller| Selected Item Encoder: LlamaOperator
[00:00:02] |Controller| Selected User Encoder: LlamaOperator
[00:00:02] |Controller| Selected Predictor: DotPredictor
[00:00:02] |Controller| Use Negative Sampling: False
[00:00:02] |Controller| Use Item Content: True
[00:00:00] |Worker| START TIME: 2024-06-12 15:45:02.792316
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Llama",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:03] |Controller| Selected Item Encoder: LlamaOperator
[00:00:03] |Controller| Selected User Encoder: LlamaOperator
[00:00:03] |Controller| Selected Predictor: DotPredictor
[00:00:03] |Controller| Use Negative Sampling: False
[00:00:03] |Controller| Use Item Content: True
[00:00:00] |Worker| START TIME: 2024-06-12 15:50:32.435635
[00:00:00] |Worker| python  worker.py --embed config/embed/ednerd-llama.yaml --model config/model/llm/ebnerd-llama-naml.yaml --exp config/exp/ebnerd-tt-naml.yaml --data config/data/ebnerd-llama.yaml --version small --llm_ver 7b --hidden_size 64 --layer 0 --lora 0 --fast_eval 0 --embed_hidden_size 4096
[00:00:00] |Worker| {
    "embed": {
        "name": "llama-full",
        "embeddings": [
            {
                "vocab_name": "article_id",
                "vocab_type": "numpy",
                "path": "ebnerd-benchmark\\data\\tokenized_llama\\data.npy",
                "frozen": true
            }
        ]
    },
    "model": {
        "name": "ebnerd-LLAMA-NAML.D64.L0.Lora0",
        "meta": {
            "item": "Llama",
            "user": "Llama",
            "predictor": "Dot"
        },
        "config": {
            "use_neg_sampling": false,
            "use_item_content": true,
            "max_item_content_batch_size": 0,
            "same_dim_transform": false,
            "embed_hidden_size": 4096,
            "hidden_size": 64,
            "item_config": {
                "llm_dir": "llama-main",
                "layer_split": 0,
                "lora": 0,
                "weights_dir": "llama-main\\llama-2-7b"
            },
            "user_config": {
                "num_attention_heads": 12,
                "inputer_config": {
                    "use_cls_token": false,
                    "use_sep_token": false
                }
            }
        }
    },
    "exp": {
        "name": "train_test",
        "dir": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test",
        "log": "saving/ebnerd-small-Llama/ebnerd-LLAMA-NAML.D64.L0.Lora0/llama-full-train_test/exp.log",
        "mode": "train_test",
        "load": {
            "save_dir": null,
            "epochs": null,
            "model_only": true,
            "strict": true,
            "wait": false
        },
        "store": {
            "metric": "GAUC",
            "maximize": true,
            "top": 1,
            "early_stop": 2
        },
        "policy": {
            "epoch_start": 0,
            "epoch": 50,
            "lr": 0.0001,
            "item_lr": 1e-05,
            "freeze_emb": false,
            "pin_memory": false,
            "epoch_batch": 0,
            "batch_size": 64,
            "accumulate_batch": 1,
            "device": "gpu",
            "n_warmup": 0,
            "check_interval": -2,
            "simple_dev": false
        },
        "metrics": [
            "GAUC",
            "MRR",
            "NDCG@1",
            "NDCG@5",
            "NDCG@10"
        ]
    },
    "data": {
        "name": "ebnerd-small-Llama",
        "base_dir": "ebnerd-benchmark\\data",
        "item": {
            "filter_cache": true,
            "depot": "ebnerd-benchmark/data/tokenized_llama",
            "order": [
                "title",
                "subtitle",
                "body",
                "category_str",
                "article_type",
                "topics",
                "total_inviews",
                "total_pageviews"
            ],
            "append": [
                "article_id"
            ]
        },
        "user": {
            "filter_cache": true,
            "depots": {
                "train": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/train"
                },
                "test": {
                    "path": "ebnerd-benchmark/data/tokenized_bert/validation"
                }
            },
            "candidate_col": "article_id",
            "clicks_col": "article_id",
            "label_col": "article_ids_clicked",
            "group_col": "impression_id",
            "user_col": "user_id",
            "index_col": "index"
        }
    },
    "version": "small",
    "llm_ver": "7b",
    "hidden_size": 64,
    "layer": 0,
    "lora": 0,
    "fast_eval": 0,
    "embed_hidden_size": 4096,
    "warmup": 0,
    "simple_dev": false,
    "batch_size": 64,
    "acc_batch": 1,
    "lora_r": 32,
    "lr": 0.0001,
    "item_lr": 1e-05,
    "mind_large_submission": false,
    "epoch_batch": 0,
    "max_item_batch_size": 0,
    "page_size": 512,
    "patience": 2,
    "epoch_start": 0,
    "frozen": true,
    "load_path": null,
    "rand": {},
    "time": {},
    "seed": 2023
}
[00:00:00] |GPU| not support cuda
[00:00:00] |GPU| switch to CPU
[00:00:00] |Controller| dataset type:  book
[00:00:00] |Controller| build column map ...
[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/train

        Sample Size: 278139
        Id Column: index
        Columns:
        	index, vocab index (size 278139)
        	impression_id, vocab impression_id (size 24724)
        	user_id, vocab user_id (size 1590)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:00] |CachingDep| load 0 filter caches on 
        UniDep (2.0): ebnerd-benchmark/data/tokenized_bert/validation

        Sample Size: 304915
        Id Column: index
        Columns:
        	index, vocab index (size 304915)
        	impression_id, vocab impression_id (size 25356)
        	user_id, vocab user_id (size 1935)
        	article_id, vocab article_id (size 11777)
        	article_ids_clicked, vocab article_ids_clicked (size 2)

[00:00:02] |Controller| Selected Item Encoder: LlamaOperator
[00:00:02] |Controller| Selected User Encoder: LlamaOperator
[00:00:02] |Controller| Selected Predictor: DotPredictor
[00:00:02] |Controller| Use Negative Sampling: False
[00:00:02] |Controller| Use Item Content: True
